<h1 id="course-outline">Course Outline</h1>
<p>Data mining digital technologies have radically transformed our social, economic, and political lives. These developments prove challenging since most of our theories of rights and justice have been developed for a non-digital society. How does this digital transformation challenge how we think about the demands of democracy and justice? Does digitalisation constitute a promise or a peril to values like equality? How does it impact the nature, scope, and content of rights and duties? This course will draw on concepts and debates from normative social and political philosophy to examine the morality and politics of these new emerging digital world.</p>
<h2 id="learning-goals">Learning Goals</h2>
<p>After completing this course, you will be able to:</p>
<dl>
<dt>LG1</dt>
<dd>
Explain the impact of digitalisation on questions of rights and justice (related to PLO 1.C.PDD)
</dd>
<dt>LG2</dt>
<dd>
Explain key concepts and theories in normative social and political philosophy and use the theories to analyse specific moral and political challenges raised by digitalization (related to PLO 2.D.PDD)
</dd>
<dt>LG3</dt>
<dd>
Critically reflect on, comment on, and evaluate philosophical analysis and argumentation found in the philosophical literature and given by peers with regard to theories of rights and justice and their application to digital societies. (related to PLO 2.A, 3. A and 3.C)
</dd>
<dt>LG4</dt>
<dd>
Critically evaluate the impact of digitalization on the promotion of rights and the pursuit of justice by constructing well-reasoned arguments about specific issues where digitalization transforms the nature, scope or content of our rights and duties (related to PLO 3.D. PDD)
</dd>
</dl>
<h2 id="general-information">General Information</h2>
<p><strong>Course coordinator:</strong></p>
<p>Miguel Egler - <a href="mailto:m.egler@tilburguniversity.edu">m.egler@tilburguniversity.edu</a> (Contact for information about the course in general)</p>
<p><strong>Practical Information</strong></p>
<p>In principle, the course will be taught <strong>on</strong> <strong>campus.</strong> Lectures will be recorded and placed on the course's Canvas page.</p>
<p>Students are expected to read the course material, submit the class assignments in a timely manner, and complete the examinations. Class attendance is <strong>not</strong> obligatory; however, it is <strong>highly</strong> recommended that you attend them regularly, or watch the recordings online.</p>
<p>The course's Canvas page will have a section dedicated to each topic of the course. There you will find updated information for each lecture, as well as study questions, required texts, additional course materials, further reading suggestions, and the recordings of each lecture (after they have taken place).</p>
<p>Special arrangements are available for students with certain circumstances, such as studying with disabilities, participating in competitive sports, or other extenuating circumstances. These are decided by the Examination Board in consultation with the Dean of Students (i.e., not by the lecturer or course coordinator). Please contact the Dean of Students (tentamenvoorziening@tilburguniversity.edu) as soon as possible if you have concerns or require special arrangements. </p>
<h2 id="assessments">Assessments</h2>
<ol>
<li><strong>Pre-session text annotation x3</strong> (50% of grade)
<ul>
<li>The assignment requires you to contribute to collectively annotating texts for seminars 2, 5 and 6. The texts will be uploaded to Perusall. Your goal in annotating the texts is to engage in an in-depth manner with the text and to stimulate discussion with peers. Concretely, this means you need to post questions or comments and help others by answering their questions or engaging with their comments. Instructions on how to sign up and use Perusall can be found on Canvas.</li>
<li>Due date: 23:59 the day before the respective seminars (e.g. the pre-session annotations for seminar 2 should be in by 23:59 of the 30th of October)</li>
<li>Grading: the annotations are self-graded by students on a scale from 0 to 3, where zero is incomplete and 3 is exceptional, following a detailed rubric that is found on canvas.</li>
<li>Self-grades due: 23:59 of Tuesday of the week following the seminar (e.g. the self-grades for seminar 2 should be in by 4th of November).</li>
<li>I will give general feedback on the annotations during the seminar. There will be no individual written feedback on these responses.</li>
</ul></li>
<li><strong>Written Exam</strong> (50% of grade)
<ul>
<li>the exam will take place on campus. The duration is 2.5 hours. The exam will contain two types open ended questions: type 1 is a short answer question requiring that you demonstrate understanding of texts and the ability to apply concepts. Type 2 is a short essay question demonstrating the ability to draw on material from the course to critically evaluate an aspect of digitalization and develop an argument in support of your reflection. Further instructions will be uploaded on Canvas in due time.</li>
<li>Exam date: 9th of December 2025</li>
</ul></li>
</ol>
<h3 id="passing-the-course">Passing the course</h3>
<p>You <strong>do not</strong> need to pass every assignment to pass the course. If the average of all your grades is 5.5 or more, then you have passed the course. For instance, a student who gets a 50/50 for the exam, and a 6/50 for the Annotations will pass the course.</p>
<h3 id="resits">Resits</h3>
<p>Students will have the opportunity for a resit for <strong>one</strong> annotation assignment and the Final Exam.</p>
<ul>
<li>Annotation resit due: Please get in touch with me by the 20th of December 2025</li>
<li>Exam resit: 13th of January 2026</li>
</ul>
<h3 id="deadlines">Deadlines</h3>
<table>
<tbody>
<tr class="odd">
<td><strong>Assessment</strong></td>
<td><strong>% of final grade</strong></td>
<td><strong>Deadline 1<sup>st</sup> attempt</strong></td>
<td><strong>Deadline Resit</strong></td>
</tr>
<tr class="even">
<td>Annotation</td>
<td>50%</td>
<td>30/10/25; 20/11/25; 27/11/25</td>
<td>TBD</td>
</tr>
<tr class="odd">
<td>Exam</td>
<td>50%</td>
<td>09/12/25</td>
<td>13/01/26</td>
</tr>
</tbody>
</table>
<h1 id="lectures-and-readings">Lectures and Readings</h1>
<h3 id="lecture-1---data-mining-and-civil-rights">Lecture 1 - Data Mining and Civil Rights</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://www.ssoar.info/ssoar/handle/document/62583">Sloane, M. (2019). Inequality is the name of the game: thoughts on the emerging field of technology, ethics and social justice. In Weizenbaum conference (p. 9). DEU.</a></li>
<li><a href="https://www.cs.yale.edu/homes/jf/Barocas-Taxonomy.pdf">Barocas, S. (2014, August). Data mining and the discourse on discrimination. In Data ethics workshop, conference on knowledge discovery and data mining (Vol. 6).</a></li>
</ul></li>
<li><p>Optional reading</p>
<ul>
<li><a href="https://faculty.cc.gatech.edu/~beki/cs4001/big-data.pdf">Croll, A., &amp; Voytek, B. (2012). Big data is our generation’s civil rights issue, and we don’t know it. Big data now, 55-59.</a></li>
<li><a href="https://mediarep.org/bitstream/handle/doc/20441/TOD_46_Phan_2022_Economies-of-Virtue_.pdf?sequence=-1#page=51">Ochigame, R. (2019). The invention of ‘ethical AI’: How big tech manipulates academia to avoid regulation. Economies of virtue, 49.</a></li>
</ul></li>
</ol>
<h3 id="lecture-2---algorithmic-injustice-in-the-courtroom">Lecture 2 - Algorithmic Injustice in the Courtroom</h3>
<ol>
<li><p>Required reading/playing/listening</p>
<ul>
<li><a href="https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/">Hao, K., &amp; Stray, J. (2019). Can you make AI fairer than a judge? Play our courtroom algorithm game. MIT Technology Review.</a></li>
<li><a href="https://hiphination.org/season-3-episodes/s3-episode-1-the-precrime-unit/">Hi-Phi Nation (2019). The Precrime Unit.</a></li>
<li><a href="https://www.bostonreview.net/articles/annette-zimmermann-algorithmic-political/">Zimmermann, A., Di Rosa, E., &amp; Kim, H. (2020). Technology can’t fix algorithmic injustice. Boston Review, 9.</a></li>
</ul></li>
</ol>
<h3 id="lecture-3---is-it-ever-ok-to-generalise">Lecture 3 - Is It Ever OK to Generalise?</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://tilburguniversity.on.worldcat.org/oclc/654291988">Chapters 2 and 3 of Schauer, F. (2003). Profiles, probabilities, and stereotypes. Harvard University Press.</a></li>
</ul></li>
</ol>
<h3 id="lecture-4---algorithmic-discrimination-1">Lecture 4 - Algorithmic Discrimination 1</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://doi.org/10.3998/ergo.12405314.0006.015">Castro, C. (2019). What's wrong with machine bias. Ergo, an Open Access Journal of Philosophy, 6.</a></li>
</ul></li>
<li><p>Optional reading</p>
<ul>
<li><a href="https://doi.org/10.1007/s10892-010-9095-6">Lippert-Rasmussen, K. (2011). “We are all Different”: Statistical Discrimination and the Right to be Treated as an Individual. The Journal of ethics, 15(1), 47-59.</a></li>
<li><a href="https://tilburguniversity.on.worldcat.org/oclc/920859219">Eidelson, B. (2015). Discrimination and disrespect. Oxford University Press.</a></li>
</ul></li>
</ol>
<h3 id="lecture-5---algorithmic-discrimination-2">Lecture 5 - Algorithmic Discrimination 2</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://direct.mit.edu/ajle/article-pdf/doi/10.1162/ajle_a_00017/1961841/ajle_a_00017.pdf">Eidelson, B. (2021). Patterned inequality, compounding injustice, and algorithmic prediction. American Journal of Law and Equality, 1, 252-276.</a></li>
</ul></li>
</ol>
<h3 id="lecture-6---democratising-ai">Lecture 6 - Democratising AI</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://philpapers.org/archive/LINDAA-2.pdf">Lin, T. A. (2024). “Democratizing AI” and the concern of algorithmic injustice. Philosophy &amp; Technology, 37(3), 103.</a></li>
</ul></li>
<li><p>Optional reading</p>
<ul>
<li><a href="https://www.seandonahue.org/_files/ugd/3eb189_b329cdc244a840ef85183218e4e87e78.pdf">Donahue, S. (Forthcoming). Should Platforms be Publicly Owned and Controlled?, Contemporary Debates. In: The Ethics of Artificial Intelligence, eds. John Zerilli, Sven Nyholm, and Atoosa Kasirzadeh. Wiley-Blackwell.</a></li>
</ul></li>
</ol>
<h3 id="lecture-7---copyright">Lecture 7 - Copyright</h3>
<ol>
<li><p>Required reading</p>
<ul>
<li><a href="https://doi.org/10.1007/s13347-024-00797-x">Shoemaker, Eric (2024). Is AI Art Theft? The Moral Foundations of Copyright Law in the Context of AI Image Generation. Philosophy and Technology 37 (3):1-21.</a></li>
</ul></li>
</ol>
